---
title: "Assignment 4  이진우  20162299"
subtitle: "Data Analysis with Applications"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document: 
    highlight: pygments
  pdf_document: default
---

<br/>

## 1. Predicting Delayed Flights
<br/>
항공기의 연착(delay) 여부를 예측하는 것은 항공사와 공항 등 항공기 운항과 관련된 주체들에게 매우 중요하다.
항공기의 연착에 따라 대체 항공기 이용료, 숙박 비용, 공항 사용료 등의 비용 발생이 매우 크기 때문이다.
FlightRecords.csv 파일은 2004년 1월동안 Washington, DC 지역으로부터 New York City로 운행한 2201개의 항공기 운행 기록을 포함한다. 본 문제에서는 다음 7개의 변수를 사용하여 항공기의 연착 여부를 예측해 본다.

- dayweek: 운행 요일 (1: Mon, 2: Tue, …, 7: Sun)
- deptime: 출발시각 (예: 1455 = 14시55분, 839: 8시39분)
- origin: 출발공항코드(DCA: Reagan Nation, IAD: Dulles, BWI: Baltimore-Washington Int’l)
- dest: 도착공항코드(JFK: Kennedy, LGA: LaGuardia, EWR: Newark)
- carrier: 항공사코드(CO: Continental, DH: Atlantic Coast, DL: Delta, MQ: American Eagle, OH: Comair, RU: Continental Express, UA: United, US: USAirways)
- weather: 날씨 (0: OK, 1: Bad)
- delay: 연착여부(“delayed” or “ontime”)

<br/>

### 1-1  
다음의 순서로 data preprocessing을 진행하자.  

- 항공기 출발시각(deptime)이 6시 이전이거나 22시 이후인 데이터는 빈도 수가 매우 적으므로 데이터셋에서 제외시킨다.  
- 수치값으로 표현되어 있는 출발시각을 6시부터 22시까지 각 시간대를 나타내는 범주형 변수로 변환한다 (Hint: 원 데이터를 100으로 나눈 후 정수값으로 내림. 그 후 factor로 변환)  
- 수치값으로 표현되어 있는 dayweek와 weather 변수를 factor로 변환한다.  
- factor로 표현되어 있는 delay 변수가 가지는 level의 순서를 “ontime”, “delayed” 순으로 변환한다 (logistic regression 수행 시에 연착하는 경우를 $P(X) = 1$로 만들기 위해서).  

```{r warning = FALSE, message=FALSE}
# 사용할 패키지 추가
library(ggplot2)
library(tidyverse)
library(patchwork)
library(psych)
library(rsample)
library(caret)
library(glmnet)
library(ROCR)
library(ISLR)
library(e1071)
```
1-2에서 여러 개 그래프를 이어붙여 가시성을 높이기 위해 수업시간에서 사용하지 않은 패키지인 patchwork를 추가했습니다.


```{r 1-1}
# 데이터파일 읽기
flight <- read.csv("FlightRecords.csv")
str(flight)

# 항공기 출발시각이 6시 ~ 22시인 데이터만 포함
flight <- subset(flight, deptime > 600 & deptime < 2200)

# 출발시각을 시간대를 나타내는 범주형 변수로 변환
flight$deptime <- factor(floor(flight$deptime / 100))

# dayweek와 weather 변수를 factor로 변환
flight$dayweek <- factor(flight$dayweek, levels = c(1,2,3,4,5,6,7), labels = c("Mon", "Tue", "Wed", "Thu", "Fri", "Sat", "Sun"))
flight$weather <- factor(flight$weather, levels = c(0,1), labels = c("OK", "Bad"))

# delay 변수의 level 순서 변경
flight$delay <- factor(flight$delay, levels = c("ontime", "delayed"))

# preprocessing 후 데이터 확인
str(flight)
```


<br/>

### 1-2
요일 별 연착비율, 출발 시간대 별 연착 비율, 출발 공항 별 연착비율, 도착 공항 별 연착 비율, 항공사 별 연착비율, 날씨 별 연착 비율을 각각 그래프로 시각화해보자. 어떤 특성을 관찰할 수 있는가?

```{r 1-2}
# group_by 후 summurize 하는 과정에서 경고메시지가 뜨는데 문제는 없기에 코드 가독성을 위해 경고메시지를 뜨지 않게했습니다.
options(dplyr.summarise.inform = FALSE)

# 요일 별 연착비율 그래프 작성
dayweek_delay <- flight %>%
  group_by(dayweek,delay) %>%
  summarize(n = n()) %>% 
  mutate(pct = n/sum(n), lbl = scales::percent(pct))

p1 <- ggplot(dayweek_delay, aes(x = dayweek, y = pct, fill = delay)) +
  geom_bar(stat = "identity", position = "fill") +
  geom_text(aes(label = lbl), size = 3, position = position_stack(vjust = 0.5)) +
  scale_y_continuous(breaks = seq(0, 1, .2),label = scales::percent) +
  scale_fill_brewer(palette = "Set2") +
  labs(title = "요일 별 연착비율", y = "Proportion")

# 출발 시간대 별 연착비율 그래프 작성
deptime_delay <- flight %>%
  group_by(deptime,delay) %>%
  summarize(n = n()) %>% 
  mutate(pct = n/sum(n), lbl = scales::percent(pct))

p2 <- ggplot(deptime_delay, aes(x = deptime, y = pct, fill = delay)) +
  geom_bar(stat = "identity", position = "fill") +
  geom_text(aes(label = lbl), size = 3, position = position_stack(vjust = 0.5)) +
  scale_y_continuous(breaks = seq(0, 1, .2),label = scales::percent) +
  scale_fill_brewer(palette = "Set2") +
  labs(title = "출발 시간대 별 연착비율", y = "Proportion")

# 출발 공항 별 연착비율 그래프 작성
origin_delay <- flight %>%
  group_by(origin,delay) %>%
  summarize(n = n()) %>% 
  mutate(pct = n/sum(n), lbl = scales::percent(pct))

p3 <- ggplot(origin_delay, aes(x = origin, y = pct, fill = delay)) +
  geom_bar(stat = "identity", position = "fill") +
  geom_text(aes(label = lbl), size = 3, position = position_stack(vjust = 0.5)) +
  scale_y_continuous(breaks = seq(0, 1, .2),label = scales::percent) +
  scale_fill_brewer(palette = "Set2") +
  labs(title = "출발 공항 별 연착비율", y = "Proportion")

# 도착 공항 별 연착비율 그래프 작성
dest_delay <- flight %>%
  group_by(dest,delay) %>%
  summarize(n = n()) %>% 
  mutate(pct = n/sum(n), lbl = scales::percent(pct))

p4 <- ggplot(dest_delay, aes(x = dest, y = pct, fill = delay)) +
  geom_bar(stat = "identity", position = "fill") +
  geom_text(aes(label = lbl), size = 3, position = position_stack(vjust = 0.5)) +
  scale_y_continuous(breaks = seq(0, 1, .2),label = scales::percent) +
  scale_fill_brewer(palette = "Set2") +
  labs(title = "도착 공항 별 연착비율", y = "Proportion")

# 항공사 별 연착비율 그래프 작성
carrier_delay <- flight %>%
  group_by(carrier,delay) %>%
  summarize(n = n()) %>% 
  mutate(pct = n/sum(n), lbl = scales::percent(pct))

p5 <- ggplot(carrier_delay, aes(x = carrier, y = pct, fill = delay)) +
  geom_bar(stat = "identity", position = "fill") +
  geom_text(aes(label = lbl), size = 3, position = position_stack(vjust = 0.5)) +
  scale_y_continuous(breaks = seq(0, 1, .2),label = scales::percent) +
  scale_fill_brewer(palette = "Set2") +
  labs(title = "항공사 별 연착비율", y = "Proportion")

# 날씨 별 연착비율 그래프 작성
weather_delay <- flight %>%
  group_by(weather,delay) %>%
  summarize(n = n()) %>% 
  mutate(pct = n/sum(n), lbl = scales::percent(pct))

p6 <- ggplot(weather_delay, aes(x = weather, y = pct, fill = delay)) +
  geom_bar(stat = "identity", position = "fill") +
  geom_text(aes(label = lbl), size = 3, position = position_stack(vjust = 0.5)) +
  scale_y_continuous(breaks = seq(0, 1, .2),label = scales::percent) +
  scale_fill_brewer(palette = "Set2") +
  labs(title = "날씨 별 연착비율", y = "Proportion")


# 그래프 시각화
p1 / p2 + plot_layout(guides = 'collect')
(p3 + p4) / (p5 + p6) + plot_layout(guides = 'collect')
```
  
요일 중에는 토요일이 비교적 연착비율이 낮고  
출발 시간 중에는 19시대가 연착 비율이 타 시간대에 비해 상당히 높습니다.  
출발 공항이 DCA인 경우와 도착 공항이 LGA인 경우 연착비율이 다소 낮으며  
항공사에 따른 연착비율은 연착비율이 약 10번 중 한번 정도인 DL, OH, US와 약 4번에 한번 정도인 CO, MQ 는
상당히 차이가 있습니다.  
날씨가 안좋은 날에는 100% 연착됩니다.


<br/>

### 1-3
7개의 모든 변수들 간의 상관관계를 시각화해보자. 어떤 특성을 관찰할 수 있는가?
```{r 1-3}
# 변수들 간의 상관 관계 그래프 작성
pairs.panels(flight[c("dayweek", "deptime", "origin", "dest", "carrier", "weather", "delay")])
```
  
날씨가 안좋을 경우 100% 연착되기 때문에 날씨와 연착이 양의 상관관계가 있고  
타 시간대에 비해 19시대에 상당히 높은 연착비율이 있었기 때문에 출발시간과 연착이 양의 상관관계가 있습니다.  
항공사별로 허브 공항에 차이가 있어서인지 항공사와 출발 공항, 항공사와 도착 공항이 약간의 상관관계가 있고 나머지 변수들 간에는 상관관계가 거의 없습니다.

<br/>

### 1-4
데이터셋을 70:30 비율로 training set과 test set으로 분할하자. 이때 stratified sampling을 활용하여 두 set에서 delay 변수의 분포가 크게 차이가 없도록 분할하자.
```{r 1-4}
# stratified sampling 적용 set 분할
set.seed(201)
split <- initial_split(flight, prop = 0.7, strata = "delay")
flight_train <- training(split)
flight_test <- testing(split)

# 분할된 set에서 delay 변수 분포 확인
sum(flight_train$delay=="ontime") / count(flight_train)
sum(flight_test$delay=="ontime") / count(flight_test)
```
training set과 test set이 차이가 없게 분할되었습니다.


<br/>

### 1-5
데이터시각화로부터 weather 변수가 “Bad” 인 경우에는 항상 항공기가 연착되는 것을 관찰할 수 있다. 따라서 weather가 Bad이면 항공기가 연착되고, weather가 OK일 경우 항공기가 연착되지 않는 것으로 예측하는 단순한 모델을 baseline model이라 하자. Test set에 baseline model을 적용했을 때 confusion matrix를 계산해 보세요.
```{r 1-5}
# baseline model의 confusion matrix
pred_base <- factor(sign(flight_test$weather=="Bad"), levels=c(0,1), labels=c("ontime", "delayed"))
confusionMatrix(pred_base, flight_test$delay, positive="delayed")
```
|Accuracy|Sensitivity|Specificity|
|:------:|:---------:|:---------:|
|0.8253  |0.07377    |1.0000     |

날씨가 좋지만 연착된 경우가 113번 있었기에 Sensitivity가 상당히 낮습니다.  



<br/>

### 1-6
Training set을 대상으로, 연착여부(delay)를 나머지 모든 변수를 사용하여 예측하기 위한 logistic
regression model을 수립해보자.

1) 변수 deptime19의 regression coefficient에 대한 추정값은 얼마인가? 이 추정값을 바탕으로 출발시각이 19시대인 항공기에 대해서 어떠한 해석을 할 수 있는가? (Hint: 범주형 변수 deptime을 model에 추가할 때 deptime6을 제외한 deptime7 ~ deptime21에 대한 dummy 변수가 만들어진다.)

```{r 1-6-1}
# delay를 제외한 변수를 포함하는 logistic regression model
model1 <- glm(delay~dayweek+deptime+origin+dest+carrier+weather, data = flight_train, family = "binomial")
summary(model1)
```
deptime19의 regression coefficient 추정값은 **2.79779**이고 통계적으로 유의합니다.  
다른 변수는 변하지 않았을 때 출발 시간대가 19시이면 odds가 e^2.79779 = 16.4083배 증가합니다.  
p(X) = 0.5 이상일 때 연착된다고 가정하면 p(X) = 0.5 일 때 odds = 1 이므로 원래 odds가 0.061 (= p(X)가 0.057) 이상일 경우  
시간대가 19시라면 16.4083배되므로 odds가 1이 넘어가고 p(X)가 0.5가 넘어가게 되어 연착으로 예측하게됩니다.  
1-2에서 확인대로 19시대의 항공기는 상당 비율로 연착되는데 그에 맞게 regression coefficient 추정값도 크고 유의하게 나왔습니다.




<br/>

2) 날씨에 문제가 없는 금요일 15시에 IAD에서 출발하여 JFK로 도착한 Delta 항공기가 연착될 확률은 얼마로 예측되는가?
```{r 1-6-2}
# 
DL15 <- data.frame(weather="OK", dayweek="Fri", deptime="15", origin="IAD", dest="JFK", carrier="DL")
DL15_prob <- predict(model1, DL15, type = "response")
DL15_prob
```
문제 조건의 데이터가 주어진 데이터셋에 없어서 조건에 맞는 데이터를 만들어서 확률을 구했습니다.  
날씨에 문제가 없는 금요일 15시에 IAD에서 출발하여 JFK로 도착한 Delta 항공기가 연착될 확률은 **0.2279361** 입니다.

<br/>

3) Threshold $k = 0.2,0.3,0.5,0.7$에 대해서 각각 test set에 대한 confusion matrix를 계산해 보자. 어떠한 경향을 관찰할 수 있는가?
```{r 1-6-3}
# test set에 대한 확률 예측
prob = predict(model1, flight_test, type="response")

# k = 0.2 일 때 confusion matrix
pred_t02 <- rep("ontime", 647)
pred_t02[prob > 0.2] <- "delayed"
confusionMatrix(factor(pred_t02, levels=c("ontime", "delayed")), flight_test$delay, positive = "delayed")

# k = 0.3 일 때 confusion matrix
pred_t03 <- rep("ontime", 647)
pred_t03[prob > 0.3] <- "delayed"
confusionMatrix(factor(pred_t03, levels=c("ontime", "delayed")), flight_test$delay, positive = "delayed")

# k = 0.5 일 때 confusion matrix
pred_t05 <- rep("ontime", 647)
pred_t05[prob > 0.5] <- "delayed"
confusionMatrix(factor(pred_t05, levels=c("ontime", "delayed")), flight_test$delay, positive = "delayed")

# k = 0.7 일 때 confusion matrix
pred_t07 <- rep("ontime", 647)
pred_t07[prob > 0.7] <- "delayed"
confusionMatrix(factor(pred_t07, levels=c("ontime", "delayed")), flight_test$delay, positive = "delayed")
```
k  |Accuracy|Sensitivity|Specificity|
:-:|:------:|:---------:|:---------:|
0.2|0.6893  |0.5902     |0.7124     |
0.3|0.7975  |0.45902    |0.87619    |
0.5|0.8485  |0.22131    |0.99429    |
0.7|0.8284  |0.09836    |0.99810    |

k가 커질수록 실제 delayed 항공기를 delayed로 예측하는 비율인 Sensitivity가 감소하며
실제 ontime 항공기를 ontime으로 예측하는 비율인 Specificity가 증가합니다.  
k = 0.5, k = 0.7 인 경우 실제는 delayed인데 예측을 ontime으로 하는 경우가 많아져 Sensitivity가 낮습니다.  
**delayed 될 경우의 대비를 위해 어떤 항공기에 대해서 이게 delayed 되는 지를 예측하는게 중요하다고 보는데 Sensitivity 낮으면 실제 delayed 항공기를 delayed로 예측하지 못하고 ontime으로 예측해버리니까 큰 도움이 되지 않는다고 생각합니다.**


<br/>

4) Baseline model과 logistic regression model의 성능을 비교해보자. 

Baselin model은 날씨가 좋은 날은 예측을 아예 못하는 것이므로 실사용해야하는 모델로써의 가치는 없다고 할 수 있습니다.  
logistic regression model은 k = 0.3인 경우 Accuracy는 약 80%이며 Sensitivity는 약 45%로 연착된다고 예측하면 대략 두번 중 한번정도의 비율로 연착 예측을 맞출 수 있으므로 Baseline model보다 성능이 좋다고 할 수 있습니다.


<br/>

### 1-7
Training set을 대상으로, step() 함수를 활용한 backward stepwise selection을 적용하여 logistic regression model을 수립해보자.
```{r 1-7}
# backward stepwise selection 적용 logistic regression model
model2 <- step(model1, direction = "backward")

# 변수 확인
coef(model2)

# test set에 대한 확률 예측
prob_step = predict(model2, flight_test, type="response")

# k = 0.5 설정
pred_step <- rep("ontime", 647)
pred_step[prob_step > 0.5] <- "delayed"

# confusion matrix 작성
confusionMatrix(factor(pred_step, levels=c("ontime", "delayed")), flight_test$delay, positive = "delayed")
```
1) 모델에 몇 개의 변수가 포함되었는가?  
도착공항의 변수가 제외된 **31**개의 변수가 포함되었습니다.  

2) Threshold $k = 0.5$일때 test set에 대한 confusion matrix를 계산해 보자.

|Accuracy|Sensitivity|Specificity|
|:------:|:---------:|:---------:|
|0.8408  |0.18033    |0.99429    |

Accuracy와 Specificity는 괜찮게 나왔지만 실제 delayed 항공기를 ontime으로 예측하는 경우가 많아 Sensitivity가 낮게 나왔습니다.



<br/>

### 1-8
Training set을 대상으로 Lasso regression을 적용하여 logistic regression model을 수립해보자. CV의 결과 바탕으로 모델에 포함되는 feature의 수와 예측정확도를 모두 고려했을 때 적합한 모델을 선택하자.
```{r 1-8}
# feature matrix 생성
trainX <- model.matrix(delay~dayweek+deptime+origin+dest+carrier+weather, data=flight_train)[,-1]
trainY <- flight_train$delay

# lasso regression 적용 cross validation
set.seed(201)
model3 <- cv.glmnet(x=trainX, y=trainY, alpha=1, family="binomial", type.measure="class", nfolds=10)
plot(model3)

# 변수 개수 확인
model3$nzero

# lambda 값 저장
lambda <- model3$lambda[22]
coef(model3, s=lambda)

# test set에 대한 delay 확률 예측
prob_lasso = predict(model3, newx=model.matrix(delay~dayweek+deptime+origin+dest+carrier+weather, data=flight_test)[,-1], s=lambda, type="response")

# k = 0.5 설정
pred_lasso <- rep("ontime", 647)
pred_lasso[prob_lasso > 0.5] <- "delayed"

# confusion matrix 작성
confusionMatrix(factor(pred_lasso, levels=c("ontime", "delayed")), flight_test$delay, positive = "delayed")
```
1) 모델에 어떠한 변수들이 포함되었는가?  
**dayweekThu, dayweekSat, dayweekSun, deptime8, deptime12, deptime13, deptime14, deptime15, deptime19, originDCA, carrierDL, carrierMQ, carrierUS,  weatherBad**  
**14**개의 변수가 포함되었습니다.  

2) Threshold $k = 0.5$일때 test set에 대한 confusion matrix를 계산해 보자.

|Accuracy|Sensitivity|Specificity|
|:------:|:---------:|:---------:|
|0.8362  |0.13934    |0.99810    |

마찬가지로 Accuracy와 Specificity는 괜찮게 나왔지만 실제 delayed 항공기를 ontime으로 예측하는 경우가 많아 Sensitivity가 낮게 나왔습니다.  
다만 변수의 수가 줄어들었기 때문에 다른 모델에 비해 해석이 용이하다고 볼 수 있습니다.



<br/>

### 1-9
6, 7, 8번에서 수립한 logistic regression model들에 대해서, test set에 대한 성능을 나타내는 ROC Curve를 하나의 그래프로 시각화하고, AUC값을 비교해 보자.
```{r 1-9}
# 6번 ROC, AUC
pred1 <- prediction(prob, flight_test$delay, c("ontime", "delayed"))
perf1 <- performance(pred1, measure="tpr", x.measure="fpr")
auc1 <- performance(pred1, measure = "auc")

# 7번 ROC, AUC
pred2 <- prediction(prob_step, flight_test$delay, c("ontime", "delayed"))
perf2 <- performance(pred2, measure="tpr", x.measure="fpr")
auc2 <- performance(pred2, measure = "auc")

# 8번 ROC, AUC
pred3 <- prediction(prob_lasso, flight_test$delay, c("ontime", "delayed"))
perf3 <- performance(pred3, measure="tpr", x.measure="fpr")
auc3 <- performance(pred3, measure = "auc")

# ROC Curve 그래프 작성
plot(perf1, col="red", lwd=2)
plot(perf2, col="green", lwd=2, add=TRUE)
plot(perf3, col="blue", lwd=2, add=TRUE)

# AUC 값 비교
c(auc1@y.values, auc2@y.values, auc3@y.values)
```
|model       |AUC        |
|:----------:|:---------:|
|model1(6번) |0.708993   |
|model2(7번) |0.7095785  |
|model3(8번) |0.690687   |

빨간 선이 6번, 초록선이 7번, 파란 선이 8번 모델의 ROC Curve 그래프입니다.  
AUC값이 7번 모델이 가장 크기는 하지만 차이가 매우 작아 세 모델의 성능 차이는 거의 없다고 할 수 있습니다.


<br/>

### 1-10
Training set을 대상으로 k-nn을 적용해보자. 이때 train() 함수를 사용한 cross validation으로 Accuracy가 가장 높은 best 값을 찾는다.
```{r 1-10}
# k-NN 적용  cross validation
set.seed(123)
model4 <- train(data=flight_train,
                delay~dayweek+deptime+origin+dest+carrier+weather, method ="knn",
                trControl = trainControl(method="repeatedcv", number =5, repeats = 5),
                tuneGrid = data.frame(k = seq(1, 99, 2)))

# k 값에 따른 Accuracy 그래프
ggplot(model4)

# best k 값 확인
model4$bestTune

# test set에 대한 확률 예측
pred_knn <- predict(model4, flight_test)

# confusion matrix 작성
confusionMatrix(pred_knn, flight_test$delay, positive = "delayed")
```
1) best $k$ 값은 얼마인가?  
best $k$ 값은 **5** 입니다.

2) Test set에 대한 confusion matrix를 계산해 보자. 그리고 Test set에 대한 성능을 앞서 수립한 logistic regression model들과 비교해보자.

model        |Accuracy|Sensitivity|Specificity|
:-----------:|:------:|:---------:|:---------:|
model1(k=0.2)|0.6893  |0.5902     |0.7124     |
model1(k=0.3)|0.7975  |0.45902    |0.87619    |
model1(k=0.5)|0.8485  |0.22131    |0.99429    |
model1(k=0.7)|0.8284  |0.09836    |0.99810    |
model2(stepwise)|0.8408  |0.18033    |0.99429    |
model3(lasso)   |0.8362  |0.13934    |0.99810    |
model4(kNN)     |0.8161  |0.11475    |0.97905    |

model1의 k=0.2, 0.3인 모델 이외에는 모두 model4보다 Accuracy와 Specificity가 높고  
model1의 k=0.7인 모델 이외에는 모두 model4보다 Sensitivity가 높습니다.  
즉 Accuracy, Sensitivity, Specificity가 model4보다 더 좋은 model1(k=0.3), model1(k=0.5), model2, model3을 사용하는 것이 좋을 것입니다.  
  
만든 모델들 중 고르자면 1-6-3에서 언급한 것 처럼 실제 delayed 항공기를 delayed로 예측하는 것이 중요하다고 생각하기 때문에 Accuracy가 약 80%로 다른 모델과 크게 차이 없고 Sensitivity가 다른 모델에 비해 확연히 높은 Threshold k = 0.3 logistic regression model인 model1(k=0.3)을 선택하겠습니다.



<br/>

## 2. OJ Dataset
ISLR 패키지에 속해 있는 OJ 데이터셋은 Citrus Hill과 Minute Maid Orange Juice를 구매한 1,070명의 고객에 대한 정보를 포함한다. 고객 및 제품 정보를 담고 있는 17개의 feature를 사용하여 고객이 두 제품 중 어떤 것을 구매할지(Purchase 변수) 예측하는 모델을 SVM을 활용하여 만들어본다. Linear, RBF, Polynomial Kernel을 사용한 SVM 모델을 만들어보고 성능을 비교해보자. 어떤 SVM 모델이 가장 좋은 성능을 보이는가?

<br/>

#### Linear Kernel
```{r 2-1}
# OJ 데이터 확인
str(OJ)

# target의 비율 확인
table(OJ$Purchase)

# train set과 test set으로 데이터 분할
set.seed(202)
OJ_split <- initial_split(OJ, prop = 0.7, strata = "Purchase")
OJ_train <- training(OJ_split)
OJ_test <- testing(OJ_split)


# parameter tuning
set.seed(202)
ln_tune.out <- tune(svm, Purchase~., data=OJ_train, kernel="linear",
                    ranges=list(cost=c(0.01, 0.1, 1, 10, 1000)))

summary(ln_tune.out)

# confusionmatrix로 test set에 대한 성능평가
ln_pred <- predict(ln_tune.out$best.model, OJ_test)
confusionMatrix(ln_pred, OJ_test$Purchase)
```
<br/>

#### RBF Kernel
```{r 2-2}
# parameter tuning
set.seed(202)
rbf_tune.out <- tune(svm, Purchase~., data=OJ_train, kernel="radial",
                     ranges=list(cost=c(0.01, 0.1, 1, 10, 1000),
                                 gamma=c(0.01, 0.1, 1, 10, 100)))

summary(rbf_tune.out)

# confusionmatrix로 test set에 대한 성능평가
rbf_pred <- predict(rbf_tune.out$best.model, OJ_test)
confusionMatrix(rbf_pred, OJ_test$Purchase)
```
<br/>

#### Polynomial Kernel
```{r 2-3}
# parameter tuning
set.seed(202)
pl_tune.out <- tune(svm, Purchase~., data=OJ_train, kernel="polynomial",
                     ranges=list(cost=c(0.01, 0.1, 1, 10, 1000),
                                 degree=c(2,3,4)))

summary(pl_tune.out)

# confusionmatrix로 test set에 대한 성능평가
pl_pred <- predict(pl_tune.out$best.model, OJ_test)
confusionMatrix(pl_pred, OJ_test$Purchase)
```
Kernel    |Accuracy|Sensitivity|Specificity|
:--------:|:------:|:---------:|:---------:|
Linear    |0.8344  |0.9179     |0.7040     |
RBF       |0.8375  |0.9128     |0.7200     |
Polynomial|0.8312  |0.9282     |0.6800     |

세개의 SVM 모델의 Accuracy, Sensitivity, Specificity가 모두 비슷한 결과가 나옵니다.  
RBF Kernel SVM 모델이 미세하게나마 Accuracy와 Specificity가 더 높기 때문에 RBF Kernel SVM 모델의 성능이 다른 두 모델보다 성능이 조금 더 좋다고 할 수 있습니다.
  
Sensitivity에 비해 Specificity가 꽤 낮은 결과가 나왔는데 이는 실제 MM을 샀지만 예측은 CH으로 한 경우가 많다는 뜻이고 즉 **MM은 예측한 것보다 더 많이 팔린다는 것**입니다.  
만약 CH와 MM을 생산하는 공장이 새로운 데이터를 받아서 이 모델로 필요한 CH와 MM의 물량을 예측한다고 하면 MM은 예측한 수보다 많이 구매될 것이므로 예측된 수보다 여유롭게 물량을 생산할 필요가 있다고 생각합니다. 






